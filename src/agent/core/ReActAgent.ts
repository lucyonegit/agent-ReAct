import { ChatOpenAI } from '@langchain/openai';
import { ChatAlibabaTongyi } from '@langchain/community/chat_models/alibaba_tongyi';
import { HumanMessage, AIMessage, SystemMessage } from '@langchain/core/messages';
import { BaseChatModel } from '@langchain/core/language_models/chat_models';
import { ToolRegistry } from '../tools/ToolRegistry.js';
import { StreamManager } from './stream/StreamManager.js';
import { 
  AgentConfig, 
  AgentConfigSchema, 
  ReActStep, 
  StreamEvent,
  AgentContext,
  TaskStep,
  TaskStatus,
  ConversationEvent,
  NormalEventData,
  TaskPlanEventData,
  ToolCallEventData
} from '../types/index.js';
import { prompt } from './config/prompt';



// ä½¿ç”¨ç±»å‹å®šä¹‰ä¸­çš„ TaskStep

/**
 * ReActæ¶æ„Agentå®ç°
 * ReAct = Reasoning + Acting
 */
export class ReActAgent {
  private llm: BaseChatModel;
  private toolRegistry: ToolRegistry;
  private config: AgentConfig;
  private streamManager: StreamManager;

  // å…±äº«çš„ Planner è®¡åˆ’åˆ—è¡¨ï¼ˆåœ¨ä¸€æ¬¡ run çš„å¤šè½® ReAct ä¸­å¤ç”¨ä¸æ›´æ–°ï¼‰
  private planList: TaskStep[] = [];

  // ä¼šè¯ç®¡ç†
  private currentSessionId: string | null = null;
  
  // ç”Ÿæˆå”¯ä¸€ID
  private genId(prefix: string): string {
    return `${prefix}_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
  }

  constructor(config: Partial<AgentConfig> = {}) {
    this.config = AgentConfigSchema.parse(config);
    this.llm = this.createLLM();
    this.toolRegistry = new ToolRegistry();
    this.streamManager = new StreamManager();
  }
  /**
   * åˆ›å»ºLLMå®ä¾‹
   */
  private createLLM(): BaseChatModel {
    const modelName = this.config.model.toLowerCase();
    if (modelName.includes('qwen') || modelName.includes('tongyi')) {
      return new ChatAlibabaTongyi({
        modelName: this.config.model,
        temperature: this.config.temperature,
        maxTokens: this.config.maxTokens,
        streaming: this.config.streamOutput,
        alibabaApiKey: process.env.DASHSCOPE_API_KEY,
      });
    } else {
      return new ChatOpenAI({
        modelName: this.config.model,
        temperature: this.config.temperature,
        maxTokens: this.config.maxTokens,
        streaming: this.config.streamOutput,
      });
    }
  }

  /**
   * å°†ä¸‹ä¸€ä¸ª pending é¡¹æ ‡è®°ä¸º doing
   */
  private markNextPendingDoing(note?: string): void {
    const item = this.planList.find(p => p.status === 'pending');
    if (item) {
      item.status = 'doing';
      if (note) item.note = note;
    }
  }

  /**
   * å°†å½“å‰ doing é¡¹æ ‡è®°ä¸º done
   */
  private markCurrentStepDone(note?: string): void {
    const item = this.planList.find(p => p.status === 'doing');
    if (item) {
      item.status = 'done';
      if (note) item.note = note;
    }
  }

  /**
   * é€šè¿‡æµäº‹ä»¶æ¨é€è®¡åˆ’æ›´æ–°
   */
  private emitPlanUpdate(
    sessionId: string,
    conversationId: string, 
    onStream?: (e: StreamEvent) => void
  ): void {
    const eventId = this.genId('plan_update');
    this.emitTaskPlan(
      { step: this.planList }, 
      sessionId, 
      conversationId, 
      eventId, 
      onStream
    );
  }

  /**
   * å¯¹å¤– APIï¼šå¸¦ session çš„è¿è¡Œ
   * å¦‚æœªä¼  sessionIdï¼Œé¦–æ¬¡è‡ªåŠ¨åˆ›å»ºå¹¶è¿”å›ï¼›è¿”å›ç»“æ„åŒ…å« sessionId ä¸ conversationId
   */
  async runWithSession(
    input: string,
    options?: { sessionId?: string; onStream?: (event: StreamEvent) => void }
  ): Promise<{ sessionId: string; conversationId: string; finalAnswer: string }> {
    const sessionId = options?.sessionId ?? (this.currentSessionId ?? this.genId('sess'));
    this.currentSessionId = sessionId;
    const conversationId = this.genId('conv');
    // ç”Ÿæˆé¢„å¤„ç†æç¤º
    await this.generatePreActionTip(input, conversationId, sessionId, options?.onStream);
    // è¿›å…¥æ¨ç†å¾ªç¯
    const finalAnswer = await this.runInternal(input, sessionId, conversationId, options?.onStream);
    return { sessionId, conversationId, finalAnswer };
  }

  /**
   * å†…éƒ¨æ¨ç†å¾ªç¯ï¼ˆå¸¦ session/conversation è¯­ä¹‰ï¼‰
   */
  private async runInternal(
    input: string,
    sessionId: string,
    conversationId: string,
    onStream?: (event: StreamEvent) => void
  ): Promise<string> {
    const context: AgentContext = {
      input,
      steps: [],
      tools: this.toolRegistry.getAllTools(),
      config: this.config
    };

    for (let iteration = 0; iteration < this.config.maxIterations; iteration++) {
      try {
        // 1ï¸âƒ£ å‘é€æ€è€ƒäº‹ä»¶ï¼ˆç‹¬ç«‹çš„ normal_eventï¼‰
        const thought = await this.generateThought(context, onStream, conversationId, sessionId);
        context.steps.push({
          type: 'thought',
          content: thought
        });

        // 2ï¸âƒ£ å†³ç­–è¡ŒåŠ¨å¹¶å‘é€å†³ç­–äº‹ä»¶ï¼ˆç‹¬ç«‹çš„ normal_eventï¼‰
        const actionDecision = await this.decideAction(context, onStream, conversationId, sessionId);
        
        if (actionDecision.type === 'final_answer') {
          // æ ‡è®°å½“å‰æ­¥éª¤ä¸ºå®Œæˆ
          this.markCurrentStepDone('âœ… å·²å®Œæˆ');
          this.emitPlanUpdate(sessionId || 'default', conversationId || 'default', onStream);
          
          // å‘é€æœ€ç»ˆç­”æ¡ˆå‡†å¤‡äº‹ä»¶
          this.emitNormal({ 
            content: '**å‡†å¤‡ç­”æ¡ˆ** - å·²æ”¶é›†è¶³å¤Ÿä¿¡æ¯ï¼Œæ­£åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...' 
          }, sessionId || 'default', conversationId || 'default', `prepare_answer_${iteration}`, onStream);
          
          // ä½¿ç”¨æµå¼ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
          const finalAnswer = await this.generateFinalAnswer(context, onStream, conversationId, sessionId);
          return finalAnswer;
        }

        if (actionDecision.type === 'action') {
          // æ‰§è¡ŒåŠ¨ä½œ
          const actionStep: ReActStep = {
            type: 'action',
            content: `Using tool: ${actionDecision.toolName}`,
            toolName: actionDecision.toolName,
            toolInput: actionDecision.toolInput
          };
          
          context.steps.push(actionStep);
          
          // 3ï¸âƒ£ å‘é€å·¥å…·è°ƒç”¨äº‹ä»¶ï¼ˆtool_call_eventï¼‰
          const toolEventId = `tool_${iteration}_${conversationId || Date.now()}`;
          const toolStartedAt = Date.now();
          
          console.log('ğŸ”§ å‘é€å·¥å…·è°ƒç”¨ START äº‹ä»¶:', { toolEventId, tool: actionDecision.toolName });
          
          this.emitToolCall({
            id: toolEventId,
            status: 'start',
            tool_name: actionDecision.toolName!,
            args: actionDecision.toolInput,
            iteration,
            startedAt: toolStartedAt
          }, sessionId, conversationId, toolEventId, onStream);
          
          const toolResult = await this.toolRegistry.executeTool(
            actionDecision.toolName!,
            actionDecision.toolInput
          );

          // è®°å½•è§‚å¯Ÿç»“æœ
          const observation = toolResult.success 
            ? `Tool executed successfully. Result: ${JSON.stringify(toolResult.result)}`
            : `Tool execution failed. Error: ${toolResult.error}`;

          const observationStep: ReActStep = {
            type: 'observation',
            content: observation,
            toolName: actionDecision.toolName,
            toolOutput: toolResult
          };

          context.steps.push(observationStep);
          
          // å·¥å…·è°ƒç”¨ç»“æŸäº‹ä»¶
          const toolFinishedAt = Date.now();
          
          console.log('ğŸ”§ å‘é€å·¥å…·è°ƒç”¨ END äº‹ä»¶:', { toolEventId, success: toolResult.success, durationMs: toolFinishedAt - toolStartedAt });
          
          this.emitToolCall({
            id: toolEventId,
            status: 'end',
            tool_name: actionDecision.toolName!,
            args: actionDecision.toolInput,
            result: toolResult,
            success: toolResult.success,
            startedAt: toolStartedAt,
            finishedAt: toolFinishedAt,
            durationMs: toolFinishedAt - toolStartedAt,
            iteration
          }, sessionId, conversationId, toolEventId, onStream);
          
          // 4ï¸âƒ£ å‘é€è§‚å¯Ÿäº‹ä»¶ï¼ˆç‹¬ç«‹çš„ normal_eventï¼‰
          await this.generateObservation(toolResult, actionDecision.toolName!, onStream, conversationId, sessionId, iteration);
          
          // 5ï¸âƒ£ æ ‡è®°å½“å‰æ­¥éª¤å®Œæˆï¼Œæ¨è¿›åˆ°ä¸‹ä¸€æ­¥
          if (toolResult.success) {
            this.markCurrentStepDone(`âœ… å·²ä½¿ç”¨ ${actionDecision.toolName}`);
            this.emitPlanUpdate(sessionId || 'default', conversationId || 'default', onStream);
          }
        }
      } catch (error) {
        const errorMessage = error instanceof Error ? error.message : 'Unknown error occurred';
        this.emitNormal({ content: `âŒ é”™è¯¯ï¼š${errorMessage}` }, sessionId, conversationId, `error_${iteration}`, onStream);
        throw new Error(`ReAct execution failed: ${errorMessage}`);
      }
    }

    // å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    const finalAnswer = await this.generateFinalAnswer(context, onStream, conversationId, sessionId);
    return finalAnswer;
  }

  /**
   * ç”Ÿæˆåˆå§‹è®¡åˆ’ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼Œå¯æ›¿æ¢ä¸ºçœŸå® Plannerï¼‰
   */
  private async generatePlanIfNeeded(
    context: AgentContext,
    onStream?: (event: StreamEvent) => void,
    conversationId?: string,
    sessionId?: string
  ): Promise<void> {
    if (this.planList && this.planList.length > 0) return;

    // è®© LLM è¾“å‡ºä¸€ä¸ª JSON æ•°ç»„çš„æ­¥éª¤è®¡åˆ’ï¼Œå°½é‡ç»“æ„åŒ–ï¼Œå¤±è´¥åˆ™ä½¿ç”¨å…œåº•
    const sys = this.buildSystemPrompt();
    const history = this.buildConversationHistory(context);
    const messages = [
      new SystemMessage(sys),
      ...history,
      new HumanMessage(prompt.createPlannerPrompt()),
    ];

    try {
      const resp = await this.llm.invoke(messages);
      const txt = (resp.content as string).trim();
      let plan: Array<{ title: string }> = [];
      try {
        // å°è¯•æå– JSON æ®µè½
        const jsonMatch = txt.match(/\[[\s\S]*\]/);
        const jsonStr = jsonMatch ? jsonMatch[0] : txt;
        const parsed = JSON.parse(jsonStr);
        if (Array.isArray(parsed)) {
          plan = parsed
            .map((p) => (typeof p === 'string' ? { title: p } : p))
            .filter((p) => p && typeof p.title === 'string' && p.title.trim().length > 0);
        }
      } catch {
        // å¿½ç•¥è§£æé”™è¯¯ï¼Œèµ°å…œåº•
      }
      if (!plan || plan.length === 0) {
        plan = [
          { title: 'åˆ†æé—®é¢˜ä¸åˆ¶å®šè®¡åˆ’' },
          { title: 'æ‰§è¡Œå¿…è¦çš„å·¥å…·åŠ¨ä½œè·å–ä¿¡æ¯' },
          { title: 'æ•´ç†è§‚å¯Ÿå¹¶æ’°å†™ç­”æ¡ˆ' },
        ];
      }
      this.planList = plan.map((p, i) => ({
        id: `plan_${i + 1}`,
        title: p.title,
        status: 'pending' as TaskStatus,
      }));
    } catch {
      // LLM è°ƒç”¨å¼‚å¸¸å…œåº•
      this.planList = [
        { id: 'plan_1', title: 'åˆ†æé—®é¢˜ä¸åˆ¶å®šè®¡åˆ’', status: 'pending' as TaskStatus },
        { id: 'plan_2', title: 'æ‰§è¡Œå¿…è¦çš„å·¥å…·åŠ¨ä½œè·å–ä¿¡æ¯', status: 'pending' as TaskStatus },
        { id: 'plan_3', title: 'æ•´ç†è§‚å¯Ÿå¹¶æ’°å†™ç­”æ¡ˆ', status: 'pending' as TaskStatus },
      ];
    }

    // // æ¨é€ä»»åŠ¡è§„åˆ’å¡ç‰‡
    // const eventId = this.genId('plan_init');
    // this.emitTaskPlan(
    //   { step: this.planList }, 
    //   sessionId || 'default', 
    //   conversationId || 'default', 
    //   eventId, 
    //   onStream
    // );
  }
  
  private async generatePreActionTip(
    input: string,
    conversationId: string,
    sessionId: string,
    onStream?: (event: StreamEvent) => void,
  ): Promise<string> { 
    const preActionprompt = prompt.createPreActionPrompt(input);
    const response = await this.llm.stream([new SystemMessage(preActionprompt), new HumanMessage(input)]);
    const preActionEventId = this.genId('pre_action'); 
    let preActionTip = ''
    for await (const chunk of response) {
      preActionTip += chunk.content;
      this.emitNormal({
        content: chunk.content as string,
        stream:true
      }, sessionId, conversationId, preActionEventId, onStream);
    }
    return preActionTip;
  }

  /**
   * ç”Ÿæˆæ€è€ƒæ­¥éª¤ï¼ˆä½œä¸ºç‹¬ç«‹çš„ normal_eventï¼‰
   */
  private async generateThought(
    context: AgentContext, 
    onStream?: (event: StreamEvent) => void,
    conversationId?: string,
    sessionId?: string
  ): Promise<string> {
    // 1) ç¡®ä¿æœ¬è½®å…±äº«çš„è®¡åˆ’å·²ç”Ÿæˆ
    await this.generatePlanIfNeeded(context, onStream, conversationId, sessionId);
    // 2) å¦‚æœå½“å‰æ²¡æœ‰è¿›è¡Œä¸­çš„æ­¥éª¤ï¼Œåˆ™æ¨è¿›ä¸€ä¸ª pending ä¸º doing
    const hasDoing = this.planList.some((p) => p.status === 'doing');
    if (!hasDoing) {
      this.markNextPendingDoing('å¼€å§‹æœ¬æ­¥éª¤æ¨ç†');
      this.emitPlanUpdate(sessionId || 'default', conversationId || 'default', onStream);
    }

    const currentStep =
      this.planList.find((p) => p.status === 'doing') ||
      this.planList.find((p) => p.status === 'pending');

    const systemPrompt = this.buildSystemPrompt();
    const conversationHistory = this.buildConversationHistory(context);

    const messages = [
      new SystemMessage(systemPrompt),
      new SystemMessage(`Current plan step: ${currentStep ? currentStep.title : 'General reasoning'}
Your task now: reason specifically for this step, think step-by-step, and determine the next logical action for THIS step.`),
      ...conversationHistory,
      new HumanMessage(`
        Based on the conversation so far, what should I think about next?
        
        CRITICAL REQUIREMENTS:
        1. Output ONLY 1-2 sentences (maximum 50 Chinese characters)
        2. State ONLY what you're thinking about RIGHT NOW
        3. NO explanations, NO details, NO reasoning process
        4. Just the current thought, nothing more
        
        âœ… Good examples:
        "éœ€è¦æŸ¥è¯¢æç™½çš„ä¿¡æ¯"
        "åˆ†æç”¨æˆ·é—®é¢˜çš„å…³é”®è¦ç´ "
        "å‡†å¤‡ä½¿ç”¨æœç´¢å·¥å…·"
        
        âŒ Bad examples (TOO LONG, avoid):
        "é¦–å…ˆæˆ‘éœ€è¦ç†è§£ç”¨æˆ·çš„é—®é¢˜ï¼Œç”¨æˆ·æƒ³è¦äº†è§£..."
        "è®©æˆ‘æ¥åˆ†æä¸€ä¸‹è¿™ä¸ªé—®é¢˜çš„å„ä¸ªæ–¹é¢..."
      `)
    ];

    const streamEventId = `thought_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    
    // å¦‚æœå¯ç”¨äº†æµå¼è¾“å‡ºä¸”æœ‰å›è°ƒå‡½æ•°
    if (this.config.streamOutput && onStream) {
      // æµå¼æ¨¡å¼
      const stream = await this.llm.stream(messages);
      let fullContent = '';
      
      for await (const chunk of stream) {
        const content = chunk.content as string;
        if (content) {
          fullContent += content;
          this.emitNormal({ content, stream: true }, sessionId || 'default', conversationId || 'default', streamEventId, onStream);
        }
      }
      
      this.emitNormal({ content: '', stream: true, done: true }, sessionId || 'default', conversationId || 'default', streamEventId, onStream);
      return fullContent;
    } else {
      // éæµå¼æ¨¡å¼
      const response = await this.llm.invoke(messages);
      const content = response.content as string;
      
      if (onStream) {
        this.emitNormal({ content }, sessionId || 'default', conversationId || 'default', streamEventId, onStream);
      }
      
      return content;
    }
  }

  /**
   * å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œï¼ˆä½œä¸ºç‹¬ç«‹çš„ normal_eventï¼‰
   */
  private async decideAction(
    context: AgentContext,
    onStream?: (event: StreamEvent) => void,
    conversationId?: string,
    sessionId?: string
  ): Promise<{
    type: 'action' | 'final_answer';
    content?: string;
    toolName?: string;
    toolInput?: any;
  }> {
    const systemPrompt = this.buildSystemPrompt();
    const conversationHistory = this.buildConversationHistory(context);
    const toolsDescription = this.toolRegistry.getToolsDescription();

    const messages = [
      new SystemMessage(systemPrompt),
      ...conversationHistory,
      new HumanMessage(`
        Available tools:
        ${toolsDescription}
        
        Based on your previous thought, decide what to do next:
        1. If you need to use a tool, respond EXACTLY in this format:
        Action: [tool_name]
        Input: [tool_input_as_json]
        
        2. If you have enough information to provide a final answer, respond with:
        Final Answer: [your_complete_answer]
        
        IMPORTANT: 
        - Do NOT add extra explanation
        - Do NOT repeat the thought process
        - ONLY output the Action/Input OR Final Answer
        - Keep it SHORT and DIRECT
      `)
    ];

    const response = await this.llm.invoke(messages);
    const content = response.content as string;

    // è§£æå“åº”
    if (content.includes('Final Answer:')) {
      const finalAnswer = content.split('Final Answer:')[1].trim();
      return {
        type: 'final_answer',
        content: finalAnswer
      };
    }

    if (content.includes('Action:')) {
      const actionMatch = content.match(/Action:\s*(.+)/);
      const inputMatch = content.match(/Input:\s*(.+)/s);
      
      if (actionMatch) {
        const toolName = actionMatch[1].trim();
        let toolInput = {};
        
        if (inputMatch) {
          try {
            const inputStr = inputMatch[1].trim();
            // å°è¯•æå– JSON éƒ¨åˆ†
            const jsonMatch = inputStr.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
              toolInput = JSON.parse(jsonMatch[0]);
            } else {
              toolInput = JSON.parse(inputStr);
            }
          } catch {
            // å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²
            toolInput = { input: inputMatch[1].trim() };
          }
        }

        // å‘é€è¡ŒåŠ¨å†³ç­–äº‹ä»¶ï¼ˆç‹¬ç«‹çš„ normal_eventï¼‰
        const actionEventId = `action_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
        const actionDescription = this.formatActionDescription(toolName, toolInput);
        
        if (onStream) {
          this.emitNormal({ 
            content: actionDescription
          }, sessionId || 'default', conversationId || 'default', actionEventId, onStream);
        }

        return {
          type: 'action',
          toolName,
          toolInput
        };
      }
    }

    // é»˜è®¤è¿”å›æ€è€ƒæ›´å¤š
    return {
      type: 'action',
      toolName: 'think_more',
      toolInput: { thought: content }
    };
  }

  /**
   * æ ¼å¼åŒ–è¡ŒåŠ¨æè¿°
   */
  private formatActionDescription(toolName: string, toolInput: any): string {
    const inputStr = typeof toolInput === 'object' 
      ? Object.entries(toolInput).map(([k, v]) => `${k}: ${v}`).join(', ')
      : String(toolInput);
    return `ğŸ¯ å‡†å¤‡æ‰§è¡Œå·¥å…·: ${toolName}\nå‚æ•°: ${inputStr}`;
  }

  /**
   * ç”Ÿæˆè§‚å¯Ÿç»“æœï¼ˆä½œä¸ºç‹¬ç«‹çš„ normal_eventï¼‰
   */
  private async generateObservation(
    toolResult: any,
    toolName: string,
    onStream?: (event: StreamEvent) => void,
    conversationId?: string,
    sessionId?: string,
    iteration?: number
  ): Promise<void> {
    const observationEventId = `observation_${Date.now()}_${Math.random().toString(36).slice(2, 8)}`;
    
    let observationContent = '';
    if (toolResult.success) {
      // ç®€æ´å±•ç¤ºæˆåŠŸç»“æœ
      const resultPreview = this.formatResultPreview(toolResult.result);
      observationContent = `âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ\nç»“æœ: ${resultPreview}`;
    } else {
      observationContent = `âŒ å·¥å…·æ‰§è¡Œå¤±è´¥\né”™è¯¯: ${toolResult.error}`;
    }
    
    if (onStream) {
      this.emitNormal({ 
        content: observationContent
      }, sessionId || 'default', conversationId || 'default', observationEventId, onStream);
    }
  }

  /**
   * æ ¼å¼åŒ–ç»“æœé¢„è§ˆï¼ˆé™åˆ¶é•¿åº¦ï¼‰
   */
  private formatResultPreview(result: any): string {
    if (!result) return '(ç©º)';
    
    const resultStr = typeof result === 'string' 
      ? result 
      : JSON.stringify(result);
    
    // é™åˆ¶æ˜¾ç¤ºé•¿åº¦
    if (resultStr.length > 100) {
      return resultStr.slice(0, 100) + '...';
    }
    return resultStr;
  }

  /**
   * ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
   */
  private async generateFinalAnswer(
    context: AgentContext, 
    onStream?: (event: StreamEvent) => void,
    conversationId?: string,
    sessionId?: string
  ): Promise<string> {
    const systemPrompt = this.buildSystemPrompt();
    const conversationHistory = this.buildConversationHistory(context);
    
    const messages = [
      new SystemMessage(systemPrompt),
      ...conversationHistory,
      new HumanMessage(`Based on the above reasoning and observations, please provide a final answer to: ${context.input}

Please be concise and direct in your response.`)
    ];

    if (this.config.streamOutput && onStream) {
      // æµå¼æ¨¡å¼
      const stream = await this.llm.stream(messages);
      let fullContent = '';
      // ä¸ºæ•´ä¸ªæµå¼è¾“å‡ºä½¿ç”¨ç»Ÿä¸€çš„ IDï¼Œç¡®ä¿å‰ç«¯èƒ½æ­£ç¡®èšåˆ
      const streamEventId = `final_answer_${conversationId || Date.now()}`;
      
      for await (const chunk of stream) {
        const content = chunk.content as string;
        if (content) {
          fullContent += content;
          // æ‰€æœ‰æµå¼ç‰‡æ®µä½¿ç”¨ç›¸åŒçš„ ID
          this.emitNormal({ content, stream: true }, sessionId || 'default', conversationId || 'default', streamEventId, onStream);
        }
      }
      
      // æµå¼æ¨¡å¼ä¸‹ï¼Œå‘é€æœ€ç»ˆç­”æ¡ˆå®Œæˆäº‹ä»¶ï¼ˆä½¿ç”¨ç›¸åŒçš„ IDï¼Œæ ‡è®° doneï¼‰
      this.emitNormal({ content: '', stream: true, done: true }, sessionId || 'default', conversationId || 'default', streamEventId, onStream);
      return fullContent;
    } else {
      // éæµå¼æ¨¡å¼
      const response = await this.llm.invoke(messages);
      const content = response.content as string;
      
      // å‘é€å®Œæ•´çš„æœ€ç»ˆç­”æ¡ˆ
      if (onStream) {
        this.emitNormal({ content }, sessionId || 'default', conversationId || 'default', `final_full_${Date.now()}`, onStream);
      }
      
      return content;
    }
  }

  /**
   * æ„å»ºç³»ç»Ÿæç¤º
   */
  private buildSystemPrompt(): string {
    // TODO: è¯­è¨€æŒ‡ä»¤
    const languageInstructions = prompt.createLanguagePrompt();
    return prompt.createSystemPrompt(languageInstructions);
  }

  /**
   * æ„å»ºå¯¹è¯å†å²
   */
  private buildConversationHistory(context: AgentContext): (HumanMessage | AIMessage)[] {
    const messages: (HumanMessage | AIMessage)[] = [
      new HumanMessage(`Question: ${context.input}`)
    ];

    for (const step of context.steps) {
      if (step.type === 'thought') {
        messages.push(new AIMessage(`Thought: ${step.content}`));
      } else if (step.type === 'action') {
        messages.push(new AIMessage(`Action: ${step.content}`));
        if (step.toolInput) {
          messages.push(new AIMessage(`Input: ${JSON.stringify(step.toolInput)}`));
        }
      } else if (step.type === 'observation') {
        messages.push(new AIMessage(`Observation: ${step.content}`));
      }
    }

    return messages;
  }

  /**
   * å‘é€åº•å±‚äº‹ä»¶
   */
  private emitStreamEvent(
    sessionId: string,
    conversationId: string,
    event: ConversationEvent,
    onStream?: (event: StreamEvent) => void
  ): void {
    if (onStream) {
      const streamEvent: StreamEvent = {
        sessionId,
        conversationId,
        event,
        timestamp: Date.now()
      };
      this.streamManager.emitStreamEvent(streamEvent);
      onStream(streamEvent);
    }
  }

  /**
   * å‘é€æ™®é€šæ–‡æœ¬äº‹ä»¶
   */
  private emitNormal(
    payload: { content: string; stream?: boolean; done?: boolean },
    sessionId: string,
    conversationId: string,
    eventId: string,
    onStream?: (e: StreamEvent) => void
  ): void {
    const event: NormalEventData = {
      id: eventId,
      role: 'assistant',
      type: 'normal_event',
      content: payload.content,
      stream: payload.stream,
      done: payload.done
    };
    this.emitStreamEvent(sessionId, conversationId, event, onStream);
  }

  /**
   * å‘é€ä»»åŠ¡è®¡åˆ’äº‹ä»¶
   */
  private emitTaskPlan(
    data: { step: TaskStep[] },
    sessionId: string,
    conversationId: string,
    eventId: string,
    onStream?: (e: StreamEvent) => void
  ): void {
    const event: TaskPlanEventData = {
      id: eventId,
      role: 'assistant',
      type: 'task_plan_event',
      data
    };
    this.emitStreamEvent(sessionId, conversationId, event, onStream);
  }

  /**
   * å‘é€å·¥å…·è°ƒç”¨äº‹ä»¶
   */
  private emitToolCall(
    data: {
      id?: string;
      status?: 'start' | 'end';
      tool_name: string;
      args: any;
      result?: any;
      success?: boolean;
      startedAt?: number;
      finishedAt?: number;
      durationMs?: number;
      iteration?: number;
    },
    sessionId: string,
    conversationId: string,
    eventId: string,
    onStream?: (e: StreamEvent) => void
  ): void {
    const event: ToolCallEventData = {
      id: eventId,
      role: 'assistant',
      type: 'tool_call_event',
      data
    };
    
    console.log('ğŸ“¤ emitToolCall è°ƒç”¨:', { eventId, status: data.status, tool: data.tool_name });
    console.log('ğŸ“¤ å®Œæ•´äº‹ä»¶å¯¹è±¡:', JSON.stringify(event, null, 2));
    
    this.emitStreamEvent(sessionId, conversationId, event, onStream);
  }

  /**
   * è·å–æµç®¡ç†å™¨å®ä¾‹
   */
  getStreamManager(): StreamManager {
    return this.streamManager;
  }

  /**
   * è·å–å·¥å…·æ³¨å†Œè¡¨
   */
  getToolRegistry(): ToolRegistry {
    return this.toolRegistry;
  }

  /**
   * æ›´æ–°é…ç½®
   */
  updateConfig(newConfig: Partial<AgentConfig>): void {
    this.config = AgentConfigSchema.parse({ ...this.config, ...newConfig });
    
    // é‡æ–°åˆå§‹åŒ–LLM
    this.llm = this.createLLM();
  }
}

